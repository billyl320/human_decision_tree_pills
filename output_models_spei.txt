
R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(xtable) #for table creation for latex
> library(ggplot2)#for graphics
> library(MASS)#for qda
> library(scales)#for scientific notation
> library(RColorBrewer) #for base r plot
> library(class) #for base r plot
> library(plyr)#for obtaining means by factor
> library(e1071)#for svm
> library(tree)#for tree based methods
> 
> #defining proper scientific notation
> 
> scientific_10 <- function(x) {
+   parse(text=gsub("e", " %*% 10^", scales::scientific_format()(x)))
+ }
> 
> #custom theme
> mytheme.scat<-theme(
+ 
+ 	plot.title = element_text(size=60, face="bold", hjust = 0.5),
+ 	axis.text.x  = element_text(size=20, face="bold"),
+ 	axis.text.y=element_text(size=20, face="bold"),
+ 	axis.title.x=element_text(size=28, face='bold'),
+ 	axis.title.y=element_text(size=28, face='bold'),
+ 	strip.background=element_rect(fill="gray80"),
+ 	panel.background=element_rect(fill="gray80"),
+ 	axis.ticks= element_blank(),
+ 	axis.text=element_text(colour="black"),
+   strip.text = element_text(size=25)
+ 
+ 	)
> 
> 
> #matrix to hold results
> model_rslts<-matrix(nrow=4, ncol=2, data=0)
> colnames(model_rslts)<-c("Train", "Validation")
> rownames(model_rslts)<-c("CNN", "QDA", "SVM", "Tree")
> 
> ##importing data for traditional image histograms
> edge   <- read.table("edge.txt", sep=",", header=TRUE)
> spiral <- read.table("spiral.txt", sep=",", header=TRUE)
> elip   <- read.table("elip.txt", sep=",", header=TRUE)
> 
> #cleaning data for ggplot2 and analysis
> labs<-as.factor(c(rep(1, dim(edge)[1]), rep(2, dim(spiral)[1]), rep(3, dim(elip)[1])) )
> 
> mydata<-rbind(edge, spiral, elip)
> 
> 
> #counts plot
> temp<-as.data.frame(cbind(labs, mydata))
> labs2<-as.factor(c(rep("Edge", dim(edge)[1]), rep("Spiral", dim(spiral)[1]), rep("Ellipse", dim(elip)[1]) ))
> 
> scat<-ggplot(data=temp, aes(x = white, y = black, colour = as.factor(labs2)))+
+           geom_point(size=2)+
+           #geom_ribbon(aes(ymin=temp$lower, ymax=temp$upper), linetype=2, alpha=0.1)+
+ 	 	      ggtitle("EI for\nGalaxy Shapes")+
+ 		      xlab("White Counts")+
+ 					ylab("Black Counts")+
+ 			 		labs(colour= "Legend")+
+ 					scale_y_continuous(label=scientific_10)+
+           scale_x_continuous(label=scientific_10)+
+           mytheme.scat+
+           scale_color_discrete(breaks=c("Edge", "Spiral", "Ellipse"))+
+           theme(legend.text=element_text(size=18),
+                 legend.title=element_text(size=24))
> 
> ggsave(filename="plots/Encircled_Image_Histograms_galaxy.png", plot=scat,
+        width=9, height=7)
> 
> 
> #
> 
> #setup for validation plot
> 
> valid_results<-matrix(nrow=4, ncol=6, data=0)
> colnames(valid_results)<-c("n=3", "n=4", "n=5", "n=7", "n=10", "n=20")
> rownames(valid_results)<-c("CNN", "QDA", "SVM", "Tree")
> 
> #setup for training plot
> train_results<-matrix(nrow=4, ncol=6, data=0)
> colnames(train_results)<-c("n=3", "n=4", "n=5", "n=7", "n=10", "n=20")
> rownames(train_results)<-c("CNN", "QDA", "SVM", "Tree")
> 
> ##################################
> ## training sample size = 3
> ##################################
> 
> n=3
> 
> #cnn results for n=3
> model_rslts[1,]<-c(1.00, 0.55)
> 
> #################
> # modeling
> #################
> 
> #finding those observations to train and validate on
> 
> set.seed(76526)
> 
> #initialize objects to hold results
> qda_train<-c()
> qda_valid<-c()
> svm_train<-c()
> svm_valid<-c()
> tree_train<-c()
> tree_valid<-c()
> 
> #simuiltion size
> sim=100
> 
> for (i in 1:sim) {
+ 
+   train1<-sample(1:75,  n)
+   train2<-sample(1:223, n)
+   train3<-sample(1:225, n)
+ 
+   mytrain<-rbind(edge[train1,], spiral[train2,],
+                  elip[train3,])
+   labs_train<-as.factor(c(rep(1, n), rep(2, n),
+                           rep(3, n) ) )
+   myvalid<-rbind(edge[-train1,], spiral[-train2,],
+                  elip[-train3,])
+   labs_valid<-as.factor(c(rep(1, 75-n), rep(2, 225-n),
+                           rep(3, 223-n) ) )
+ 
+   #######
+   #QDA
+   #######
+   train<-as.data.frame(cbind(as.factor(labs_train), mytrain))
+   colnames(train)[1]<-"labs"
+ 
+   #creating model
+   qda.fit = qda(labs ~ white + black, data=train)
+   #qda.fit #rank deficiency - ie unable to compute
+ 
+   #predicting
+   qda.pred=predict(qda.fit, train)
+   qda.class = qda.pred$class
+ 
+   #results
+   #table(qda.class, labs_train)
+   #overall classification rate for training
+   qda_train[i]<- mean(qda.class==as.factor(as.numeric(labs_train)))
+ 
+   ####
+   #now predict on validation
+   valid<-as.data.frame(cbind(as.factor(labs_valid), myvalid))
+   colnames(valid)[1]<-"labs"
+ 
+   #predicting
+   qda.pred=predict(qda.fit, valid)
+   qda.class = qda.pred$class
+ 
+   #results
+   #table(qda.class, labs_valid)
+   #overall classification rate for training
+   qda_valid[i]<-mean(qda.class==as.factor(as.numeric(labs_valid)))
+ 
+   #######
+   #SVM
+   #######
+ 
+   train<-as.data.frame(cbind(as.factor(labs_train), mytrain))
+   colnames(train)[1]<-"labs"
+ 
+   valid<-as.data.frame(cbind(as.factor(labs_valid), myvalid))
+   colnames(valid)[1]<-"labs"
+ 
+   #creating model
+   svmfit=svm(labs ~ white + black, data=train, kernel="linear",
+              cost=2,#, coef0= 1, degree=2,
+              scale=FALSE)
+ 
+   #plot(svmfit , train)
+ 
+   #summary(svmfit)
+ 
+   ypred=predict(svmfit ,train)
+   #table(predict=ypred, truth=train$labs)
+   svm_train[i]<-mean(ypred==as.factor(as.numeric(labs_train)))
+ 
+   #now on valid
+   ypred_valid=predict(svmfit ,valid)
+   #table(predict=ypred_valid, truth=valid$labs)
+   svm_valid[i]<-mean(ypred_valid==as.factor(as.numeric(labs_valid)))
+ 
+   ######
+   # Tree
+   #######
+ 
+   #training tree mdoel
+   treefit =tree(labs ~ white + black, data=train )
+   #summary(treefit)
+ 
+   ypred_train=predict(treefit ,train, type='class')
+   #table(predict=ypred_train, truth=as.factor(train$labs))
+   tree_train[i]<-mean(ypred_train==as.factor(as.numeric(labs_train)))
+ 
+   #plot(treefit )
+   #text(treefit ,pretty =0)
+ 
+   ypred_valid=predict(treefit ,valid, type='class')
+   #table(predict=ypred_valid, truth=valid$labs)
+   tree_valid[i]<-mean(ypred_valid==as.factor(as.numeric(labs_valid)))
+ 
+ }

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations
> 
> #################
> ## Model Results
> #################
> 
> #QDA
> model_rslts[2,1]<-mean(qda_train)
> model_rslts[2,2]<-mean(qda_valid)
> 
> #SVM
> model_rslts[3,1]<-mean(svm_train)
> model_rslts[3,2]<-mean(svm_valid)
> 
> #tree
> model_rslts[4,1]<-mean(tree_train)
> model_rslts[4,2]<-mean(tree_valid)
> 
> sd(qda_train)
[1] 0.07652511
> sd(qda_valid)
[1] 0.09052694
> sd(svm_valid)
[1] 0.07431519
> sd(svm_train)
[1] 0.1081018
> sd(tree_train)
[1] 0.1368185
> sd(tree_valid)
[1] 0.0216247
> 
> 
> #display results
> model_rslts
         Train Validation
CNN  1.0000000  0.5500000
QDA  0.9422222  0.5553696
SVM  0.9188889  0.6065564
Tree 0.3144444  0.3317315
> 
> xtable(model_rslts, digits=2)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Tue Mar 24 12:12:05 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 & Train & Validation \\ 
  \hline
CNN & 1.00 & 0.55 \\ 
  QDA & 0.94 & 0.56 \\ 
  SVM & 0.92 & 0.61 \\ 
  Tree & 0.31 & 0.33 \\ 
   \hline
\end{tabular}
\end{table}
> 
> valid_results[,1]<-model_rslts[,2]
> train_results[,1]<-model_rslts[,1]
> 
> ##################################
> ## training sample size = 4
> ##################################
> 
> n=4
> 
> #cnn results for n=4
> model_rslts[1,]<-c(1.00, 0.56)
> 
> #################
> # modeling
> #################
> 
> #finding those observations to train and validate on
> 
> set.seed(872596)
> 
> #initialize objects to hold results
> qda_train<-c()
> qda_valid<-c()
> svm_train<-c()
> svm_valid<-c()
> tree_train<-c()
> tree_valid<-c()
> 
> #simuiltion size
> sim=100
> 
> for (i in 1:sim) {
+ 
+   train1<-sample(1:75,  n)
+   train2<-sample(1:223, n)
+   train3<-sample(1:225, n)
+ 
+   mytrain<-rbind(edge[train1,], spiral[train2,],
+                  elip[train3,])
+   labs_train<-as.factor(c(rep(1, n), rep(2, n),
+                           rep(3, n) ) )
+   myvalid<-rbind(edge[-train1,], spiral[-train2,],
+                  elip[-train3,])
+   labs_valid<-as.factor(c(rep(1, 75-n), rep(2, 225-n),
+                           rep(3, 223-n) ) )
+ 
+   #######
+   #QDA
+   #######
+   train<-as.data.frame(cbind(as.factor(labs_train), mytrain))
+   colnames(train)[1]<-"labs"
+ 
+   #creating model
+   qda.fit = qda(labs ~ white + black, data=train)
+   #qda.fit #rank deficiency - ie unable to compute
+ 
+   #predicting
+   qda.pred=predict(qda.fit, train)
+   qda.class = qda.pred$class
+ 
+   #results
+   #table(qda.class, labs_train)
+   #overall classification rate for training
+   qda_train[i]<- mean(qda.class==as.factor(as.numeric(labs_train)))
+ 
+   ####
+   #now predict on validation
+   valid<-as.data.frame(cbind(as.factor(labs_valid), myvalid))
+   colnames(valid)[1]<-"labs"
+ 
+   #predicting
+   qda.pred=predict(qda.fit, valid)
+   qda.class = qda.pred$class
+ 
+   #results
+   #table(qda.class, labs_valid)
+   #overall classification rate for training
+   qda_valid[i]<-mean(qda.class==as.factor(as.numeric(labs_valid)))
+ 
+   #######
+   #SVM
+   #######
+ 
+   train<-as.data.frame(cbind(as.factor(labs_train), mytrain))
+   colnames(train)[1]<-"labs"
+ 
+   valid<-as.data.frame(cbind(as.factor(labs_valid), myvalid))
+   colnames(valid)[1]<-"labs"
+ 
+   #creating model
+   svmfit=svm(labs ~ white + black, data=train, kernel="linear",
+              cost=2,#, coef0= 1, degree=2,
+              scale=FALSE)
+ 
+   #plot(svmfit , train)
+ 
+   #summary(svmfit)
+ 
+   ypred=predict(svmfit ,train)
+   #table(predict=ypred, truth=train$labs)
+   svm_train[i]<-mean(ypred==as.factor(as.numeric(labs_train)))
+ 
+   #now on valid
+   ypred_valid=predict(svmfit ,valid)
+   #table(predict=ypred_valid, truth=valid$labs)
+   svm_valid[i]<-mean(ypred_valid==as.factor(as.numeric(labs_valid)))
+ 
+   ######
+   # Tree
+   #######
+ 
+   #training tree mdoel
+   treefit =tree(labs ~ white + black, data=train )
+   #summary(treefit)
+ 
+   ypred_train=predict(treefit ,train, type='class')
+   #table(predict=ypred_train, truth=as.factor(train$labs))
+   tree_train[i]<-mean(ypred_train==as.factor(as.numeric(labs_train)))
+ 
+   #plot(treefit )
+   #text(treefit ,pretty =0)
+ 
+   ypred_valid=predict(treefit ,valid, type='class')
+   #table(predict=ypred_valid, truth=valid$labs)
+   tree_valid[i]<-mean(ypred_valid==as.factor(as.numeric(labs_valid)))
+ 
+ }

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations
> 
> #################
> ## Model Results
> #################
> 
> #QDA
> model_rslts[2,1]<-mean(qda_train)
> model_rslts[2,2]<-mean(qda_valid)
> 
> #SVM
> model_rslts[3,1]<-mean(svm_train)
> model_rslts[3,2]<-mean(svm_valid)
> 
> #tree
> model_rslts[4,1]<-mean(tree_train)
> model_rslts[4,2]<-mean(tree_valid)
> 
> sd(qda_train)
[1] 0.08375315
> sd(qda_valid)
[1] 0.06282152
> sd(svm_valid)
[1] 0.06834988
> sd(svm_train)
[1] 0.1104113
> sd(tree_train)
[1] 0.008333333
> sd(tree_valid)
[1] 0.0527948
> 
> 
> #display results
> model_rslts
         Train Validation
CNN  1.0000000  0.5600000
QDA  0.9166667  0.5980431
SVM  0.8841667  0.6198043
Tree 0.6658333  0.4776712
> 
> xtable(model_rslts, digits=2)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Tue Mar 24 12:12:41 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 & Train & Validation \\ 
  \hline
CNN & 1.00 & 0.56 \\ 
  QDA & 0.92 & 0.60 \\ 
  SVM & 0.88 & 0.62 \\ 
  Tree & 0.67 & 0.48 \\ 
   \hline
\end{tabular}
\end{table}
> 
> train_results[,2]<-model_rslts[,1]
> valid_results[,2]<-model_rslts[,2]
> 
> ##################################
> ## training sample size = 5
> ##################################
> 
> n=5
> 
> #cnn results for n=5
> model_rslts[1,]<-c(1.00, 0.56)
> 
> #################
> # modeling
> #################
> 
> #finding those observations to train and validate on
> 
> set.seed(50976)
> 
> #initialize objects to hold results
> qda_train<-c()
> qda_valid<-c()
> svm_train<-c()
> svm_valid<-c()
> tree_train<-c()
> tree_valid<-c()
> 
> #simuiltion size
> sim=100
> 
> for (i in 1:sim) {
+ 
+   train1<-sample(1:75,  n)
+   train2<-sample(1:223, n)
+   train3<-sample(1:225, n)
+ 
+   mytrain<-rbind(edge[train1,], spiral[train2,],
+                  elip[train3,])
+   labs_train<-as.factor(c(rep(1, n), rep(2, n),
+                           rep(3, n) ) )
+   myvalid<-rbind(edge[-train1,], spiral[-train2,],
+                  elip[-train3,])
+   labs_valid<-as.factor(c(rep(1, 75-n), rep(2, 225-n),
+                           rep(3, 223-n) ) )
+ 
+   #######
+   #QDA
+   #######
+   train<-as.data.frame(cbind(as.factor(labs_train), mytrain))
+   colnames(train)[1]<-"labs"
+ 
+   #creating model
+   qda.fit = qda(labs ~ white + black, data=train)
+   #qda.fit #rank deficiency - ie unable to compute
+ 
+   #predicting
+   qda.pred=predict(qda.fit, train)
+   qda.class = qda.pred$class
+ 
+   #results
+   #table(qda.class, labs_train)
+   #overall classification rate for training
+   qda_train[i]<- mean(qda.class==as.factor(as.numeric(labs_train)))
+ 
+   ####
+   #now predict on validation
+   valid<-as.data.frame(cbind(as.factor(labs_valid), myvalid))
+   colnames(valid)[1]<-"labs"
+ 
+   #predicting
+   qda.pred=predict(qda.fit, valid)
+   qda.class = qda.pred$class
+ 
+   #results
+   #table(qda.class, labs_valid)
+   #overall classification rate for training
+   qda_valid[i]<-mean(qda.class==as.factor(as.numeric(labs_valid)))
+ 
+   #######
+   #SVM
+   #######
+ 
+   train<-as.data.frame(cbind(as.factor(labs_train), mytrain))
+   colnames(train)[1]<-"labs"
+ 
+   valid<-as.data.frame(cbind(as.factor(labs_valid), myvalid))
+   colnames(valid)[1]<-"labs"
+ 
+   #creating model
+   svmfit=svm(labs ~ white + black, data=train, kernel="linear",
+              cost=2,#, coef0= 1, degree=2,
+              scale=FALSE)
+ 
+   #plot(svmfit , train)
+ 
+   #summary(svmfit)
+ 
+   ypred=predict(svmfit ,train)
+   #table(predict=ypred, truth=train$labs)
+   svm_train[i]<-mean(ypred==as.factor(as.numeric(labs_train)))
+ 
+   #now on valid
+   ypred_valid=predict(svmfit ,valid)
+   #table(predict=ypred_valid, truth=valid$labs)
+   svm_valid[i]<-mean(ypred_valid==as.factor(as.numeric(labs_valid)))
+ 
+   ######
+   # Tree
+   #######
+ 
+   #training tree mdoel
+   treefit =tree(labs ~ white + black, data=train )
+   #summary(treefit)
+ 
+   ypred_train=predict(treefit ,train, type='class')
+   #table(predict=ypred_train, truth=as.factor(train$labs))
+   tree_train[i]<-mean(ypred_train==as.factor(as.numeric(labs_train)))
+ 
+   #plot(treefit )
+   #text(treefit ,pretty =0)
+ 
+   ypred_valid=predict(treefit ,valid, type='class')
+   #table(predict=ypred_valid, truth=valid$labs)
+   tree_valid[i]<-mean(ypred_valid==as.factor(as.numeric(labs_valid)))
+ 
+ }

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations
> 
> #################
> ## Model Results
> #################
> 
> #QDA
> model_rslts[2,1]<-mean(qda_train)
> model_rslts[2,2]<-mean(qda_valid)
> 
> #SVM
> model_rslts[3,1]<-mean(svm_train)
> model_rslts[3,2]<-mean(svm_valid)
> 
> #tree
> model_rslts[4,1]<-mean(tree_train)
> model_rslts[4,2]<-mean(tree_valid)
> 
> sd(qda_train)
[1] 0.07734076
> sd(qda_valid)
[1] 0.05951099
> sd(svm_valid)
[1] 0.07434956
> sd(svm_train)
[1] 0.1086516
> sd(tree_train)
[1] 0.09621105
> sd(tree_valid)
[1] 0.06515179
> 
> 
> #display results
> model_rslts
         Train Validation
CNN  1.0000000  0.5600000
QDA  0.8840000  0.6230906
SVM  0.8346667  0.6193307
Tree 0.7606667  0.5308268
> 
> xtable(model_rslts, digits=2)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Tue Mar 24 12:13:42 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 & Train & Validation \\ 
  \hline
CNN & 1.00 & 0.56 \\ 
  QDA & 0.88 & 0.62 \\ 
  SVM & 0.83 & 0.62 \\ 
  Tree & 0.76 & 0.53 \\ 
   \hline
\end{tabular}
\end{table}
> 
> train_results[,3]<-model_rslts[,1]
> valid_results[,3]<-model_rslts[,2]
> 
> ##################################
> ## training sample size = 7
> ##################################
> 
> n=7
> 
> #cnn results for n=7
> model_rslts[1,]<-c(1.00, 0.58)
> 
> #################
> # modeling
> #################
> 
> #finding those observations to train and validate on
> 
> set.seed(35522)
> 
> #initialize objects to hold results
> qda_train<-c()
> qda_valid<-c()
> svm_train<-c()
> svm_valid<-c()
> tree_train<-c()
> tree_valid<-c()
> 
> #simuiltion size
> sim=100
> 
> for (i in 1:sim) {
+ 
+   train1<-sample(1:75,  n)
+   train2<-sample(1:223, n)
+   train3<-sample(1:225, n)
+ 
+   mytrain<-rbind(edge[train1,], spiral[train2,],
+                  elip[train3,])
+   labs_train<-as.factor(c(rep(1, n), rep(2, n),
+                           rep(3, n) ) )
+   myvalid<-rbind(edge[-train1,], spiral[-train2,],
+                  elip[-train3,])
+   labs_valid<-as.factor(c(rep(1, 75-n), rep(2, 225-n),
+                           rep(3, 223-n) ) )
+ 
+   #######
+   #QDA
+   #######
+   train<-as.data.frame(cbind(as.factor(labs_train), mytrain))
+   colnames(train)[1]<-"labs"
+ 
+   #creating model
+   qda.fit = qda(labs ~ white + black, data=train)
+   #qda.fit #rank deficiency - ie unable to compute
+ 
+   #predicting
+   qda.pred=predict(qda.fit, train)
+   qda.class = qda.pred$class
+ 
+   #results
+   #table(qda.class, labs_train)
+   #overall classification rate for training
+   qda_train[i]<- mean(qda.class==as.factor(as.numeric(labs_train)))
+ 
+   ####
+   #now predict on validation
+   valid<-as.data.frame(cbind(as.factor(labs_valid), myvalid))
+   colnames(valid)[1]<-"labs"
+ 
+   #predicting
+   qda.pred=predict(qda.fit, valid)
+   qda.class = qda.pred$class
+ 
+   #results
+   #table(qda.class, labs_valid)
+   #overall classification rate for training
+   qda_valid[i]<-mean(qda.class==as.factor(as.numeric(labs_valid)))
+ 
+   #######
+   #SVM
+   #######
+ 
+   train<-as.data.frame(cbind(as.factor(labs_train), mytrain))
+   colnames(train)[1]<-"labs"
+ 
+   valid<-as.data.frame(cbind(as.factor(labs_valid), myvalid))
+   colnames(valid)[1]<-"labs"
+ 
+   #creating model
+   svmfit=svm(labs ~ white + black, data=train, kernel="linear",
+              cost=2,#, coef0= 1, degree=2,
+              scale=FALSE)
+ 
+   #plot(svmfit , train)
+ 
+   #summary(svmfit)
+ 
+   ypred=predict(svmfit ,train)
+   #table(predict=ypred, truth=train$labs)
+   svm_train[i]<-mean(ypred==as.factor(as.numeric(labs_train)))
+ 
+   #now on valid
+   ypred_valid=predict(svmfit ,valid)
+   #table(predict=ypred_valid, truth=valid$labs)
+   svm_valid[i]<-mean(ypred_valid==as.factor(as.numeric(labs_valid)))
+ 
+   ######
+   # Tree
+   #######
+ 
+   #training tree mdoel
+   treefit =tree(labs ~ white + black, data=train )
+   #summary(treefit)
+ 
+   ypred_train=predict(treefit ,train, type='class')
+   #table(predict=ypred_train, truth=as.factor(train$labs))
+   tree_train[i]<-mean(ypred_train==as.factor(as.numeric(labs_train)))
+ 
+   #plot(treefit )
+   #text(treefit ,pretty =0)
+ 
+   ypred_valid=predict(treefit ,valid, type='class')
+   #table(predict=ypred_valid, truth=valid$labs)
+   tree_valid[i]<-mean(ypred_valid==as.factor(as.numeric(labs_valid)))
+ 
+ }

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations
> 
> #################
> ## Model Results
> #################
> 
> #QDA
> model_rslts[2,1]<-mean(qda_train)
> model_rslts[2,2]<-mean(qda_valid)
> 
> #SVM
> model_rslts[3,1]<-mean(svm_train)
> model_rslts[3,2]<-mean(svm_valid)
> 
> #tree
> model_rslts[4,1]<-mean(tree_train)
> model_rslts[4,2]<-mean(tree_valid)
> 
> sd(qda_train)
[1] 0.0788889
> sd(qda_valid)
[1] 0.04425192
> sd(svm_valid)
[1] 0.06256646
> sd(svm_train)
[1] 0.09320952
> sd(tree_train)
[1] 0.06886368
> sd(tree_valid)
[1] 0.06797812
> 
> 
> #display results
> model_rslts
         Train Validation
CNN  1.0000000  0.5800000
QDA  0.8461905  0.6502988
SVM  0.8271429  0.6377291
Tree 0.8266667  0.5692829
> 
> xtable(model_rslts, digits=2)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Tue Mar 24 12:15:00 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 & Train & Validation \\ 
  \hline
CNN & 1.00 & 0.58 \\ 
  QDA & 0.85 & 0.65 \\ 
  SVM & 0.83 & 0.64 \\ 
  Tree & 0.83 & 0.57 \\ 
   \hline
\end{tabular}
\end{table}
> 
> train_results[,4]<-model_rslts[,1]
> valid_results[,4]<-model_rslts[,2]
> 
> ##################################
> ## training sample size = 10
> ##################################
> 
> n=10
> 
> #cnn results for n=10
> model_rslts[1,]<-c(1.00, 0.60)
> 
> #################
> # modeling
> #################
> 
> #finding those observations to train and validate on
> 
> set.seed(1275148)
> 
> #initialize objects to hold results
> qda_train<-c()
> qda_valid<-c()
> svm_train<-c()
> svm_valid<-c()
> tree_train<-c()
> tree_valid<-c()
> 
> #simuiltion size
> sim=100
> 
> for (i in 1:sim) {
+ 
+   train1<-sample(1:75,  n)
+   train2<-sample(1:223, n)
+   train3<-sample(1:225, n)
+ 
+   mytrain<-rbind(edge[train1,], spiral[train2,],
+                  elip[train3,])
+   labs_train<-as.factor(c(rep(1, n), rep(2, n),
+                           rep(3, n) ) )
+   myvalid<-rbind(edge[-train1,], spiral[-train2,],
+                  elip[-train3,])
+   labs_valid<-as.factor(c(rep(1, 75-n), rep(2, 225-n),
+                           rep(3, 223-n) ) )
+ 
+   #######
+   #QDA
+   #######
+   train<-as.data.frame(cbind(as.factor(labs_train), mytrain))
+   colnames(train)[1]<-"labs"
+ 
+   #creating model
+   qda.fit = qda(labs ~ white + black, data=train)
+   #qda.fit #rank deficiency - ie unable to compute
+ 
+   #predicting
+   qda.pred=predict(qda.fit, train)
+   qda.class = qda.pred$class
+ 
+   #results
+   #table(qda.class, labs_train)
+   #overall classification rate for training
+   qda_train[i]<- mean(qda.class==as.factor(as.numeric(labs_train)))
+ 
+   ####
+   #now predict on validation
+   valid<-as.data.frame(cbind(as.factor(labs_valid), myvalid))
+   colnames(valid)[1]<-"labs"
+ 
+   #predicting
+   qda.pred=predict(qda.fit, valid)
+   qda.class = qda.pred$class
+ 
+   #results
+   #table(qda.class, labs_valid)
+   #overall classification rate for training
+   qda_valid[i]<-mean(qda.class==as.factor(as.numeric(labs_valid)))
+ 
+   #######
+   #SVM
+   #######
+ 
+   train<-as.data.frame(cbind(as.factor(labs_train), mytrain))
+   colnames(train)[1]<-"labs"
+ 
+   valid<-as.data.frame(cbind(as.factor(labs_valid), myvalid))
+   colnames(valid)[1]<-"labs"
+ 
+   #creating model
+   svmfit=svm(labs ~ white + black, data=train, kernel="linear",
+              cost=2,#, coef0= 1, degree=2,
+              scale=FALSE)
+ 
+   #plot(svmfit , train)
+ 
+   #summary(svmfit)
+ 
+   ypred=predict(svmfit ,train)
+   #table(predict=ypred, truth=train$labs)
+   svm_train[i]<-mean(ypred==as.factor(as.numeric(labs_train)))
+ 
+   #now on valid
+   ypred_valid=predict(svmfit ,valid)
+   #table(predict=ypred_valid, truth=valid$labs)
+   svm_valid[i]<-mean(ypred_valid==as.factor(as.numeric(labs_valid)))
+ 
+   ######
+   # Tree
+   #######
+ 
+   #training tree mdoel
+   treefit =tree(labs ~ white + black, data=train )
+   #summary(treefit)
+ 
+   ypred_train=predict(treefit ,train, type='class')
+   #table(predict=ypred_train, truth=as.factor(train$labs))
+   tree_train[i]<-mean(ypred_train==as.factor(as.numeric(labs_train)))
+ 
+   #plot(treefit )
+   #text(treefit ,pretty =0)
+ 
+   ypred_valid=predict(treefit ,valid, type='class')
+   #table(predict=ypred_valid, truth=valid$labs)
+   tree_valid[i]<-mean(ypred_valid==as.factor(as.numeric(labs_valid)))
+ 
+ }

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations
> 
> #################
> ## Model Results
> #################
> 
> #QDA
> model_rslts[2,1]<-mean(qda_train)
> model_rslts[2,2]<-mean(qda_valid)
> 
> #SVM
> model_rslts[3,1]<-mean(svm_train)
> model_rslts[3,2]<-mean(svm_valid)
> 
> #tree
> model_rslts[4,1]<-mean(tree_train)
> model_rslts[4,2]<-mean(tree_valid)
> 
> sd(qda_train)
[1] 0.06740001
> sd(qda_valid)
[1] 0.03478252
> sd(svm_valid)
[1] 0.06215972
> sd(svm_train)
[1] 0.08170119
> sd(tree_train)
[1] 0.06375722
> sd(tree_valid)
[1] 0.0524279
> 
> 
> #display results
> model_rslts
         Train Validation
CNN  1.0000000  0.6000000
QDA  0.8273333  0.6667546
SVM  0.8116667  0.6449696
Tree 0.8196667  0.5936308
> 
> xtable(model_rslts, digits=2)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Tue Mar 24 12:17:07 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 & Train & Validation \\ 
  \hline
CNN & 1.00 & 0.60 \\ 
  QDA & 0.83 & 0.67 \\ 
  SVM & 0.81 & 0.64 \\ 
  Tree & 0.82 & 0.59 \\ 
   \hline
\end{tabular}
\end{table}
> 
> train_results[,5]<-model_rslts[,1]
> valid_results[,5]<-model_rslts[,2]
> 
> ##################################
> ## training sample size = 20
> ##################################
> 
> n=20
> 
> #cnn results for n=29
> model_rslts[1,]<-c(1.00, 0.64)
> 
> #################
> # modeling
> #################
> 
> #finding those observations to train and validate on
> 
> set.seed(5924544)
> 
> #initialize objects to hold results
> qda_train<-c()
> qda_valid<-c()
> svm_train<-c()
> svm_valid<-c()
> tree_train<-c()
> tree_valid<-c()
> 
> #simuiltion size
> sim=100
> 
> for (i in 1:sim) {
+ 
+   train1<-sample(1:75,  n)
+   train2<-sample(1:223, n)
+   train3<-sample(1:225, n)
+ 
+   mytrain<-rbind(edge[train1,], spiral[train2,],
+                  elip[train3,])
+   labs_train<-as.factor(c(rep(1, n), rep(2, n),
+                           rep(3, n) ) )
+   myvalid<-rbind(edge[-train1,], spiral[-train2,],
+                  elip[-train3,])
+   labs_valid<-as.factor(c(rep(1, 75-n), rep(2, 225-n),
+                           rep(3, 223-n) ) )
+ 
+   #######
+   #QDA
+   #######
+   train<-as.data.frame(cbind(as.factor(labs_train), mytrain))
+   colnames(train)[1]<-"labs"
+ 
+   #creating model
+   qda.fit = qda(labs ~ white + black, data=train)
+   #qda.fit #rank deficiency - ie unable to compute
+ 
+   #predicting
+   qda.pred=predict(qda.fit, train)
+   qda.class = qda.pred$class
+ 
+   #results
+   #table(qda.class, labs_train)
+   #overall classification rate for training
+   qda_train[i]<- mean(qda.class==as.factor(as.numeric(labs_train)))
+ 
+   ####
+   #now predict on validation
+   valid<-as.data.frame(cbind(as.factor(labs_valid), myvalid))
+   colnames(valid)[1]<-"labs"
+ 
+   #predicting
+   qda.pred=predict(qda.fit, valid)
+   qda.class = qda.pred$class
+ 
+   #results
+   #table(qda.class, labs_valid)
+   #overall classification rate for training
+   qda_valid[i]<-mean(qda.class==as.factor(as.numeric(labs_valid)))
+ 
+   #######
+   #SVM
+   #######
+ 
+   train<-as.data.frame(cbind(as.factor(labs_train), mytrain))
+   colnames(train)[1]<-"labs"
+ 
+   valid<-as.data.frame(cbind(as.factor(labs_valid), myvalid))
+   colnames(valid)[1]<-"labs"
+ 
+   #creating model
+   svmfit=svm(labs ~ white + black, data=train, kernel="linear",
+              cost=2,#, coef0= 1, degree=2,
+              scale=FALSE)
+ 
+   #plot(svmfit , train)
+ 
+   #summary(svmfit)
+ 
+   ypred=predict(svmfit ,train)
+   #table(predict=ypred, truth=train$labs)
+   svm_train[i]<-mean(ypred==as.factor(as.numeric(labs_train)))
+ 
+   #now on valid
+   ypred_valid=predict(svmfit ,valid)
+   #table(predict=ypred_valid, truth=valid$labs)
+   svm_valid[i]<-mean(ypred_valid==as.factor(as.numeric(labs_valid)))
+ 
+   ######
+   # Tree
+   #######
+ 
+   #training tree mdoel
+   treefit =tree(labs ~ white + black, data=train )
+   #summary(treefit)
+ 
+   ypred_train=predict(treefit ,train, type='class')
+   #table(predict=ypred_train, truth=as.factor(train$labs))
+   tree_train[i]<-mean(ypred_train==as.factor(as.numeric(labs_train)))
+ 
+   #plot(treefit )
+   #text(treefit ,pretty =0)
+ 
+   ypred_valid=predict(treefit ,valid, type='class')
+   #table(predict=ypred_valid, truth=valid$labs)
+   tree_valid[i]<-mean(ypred_valid==as.factor(as.numeric(labs_valid)))
+ 
+ }

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations
> 
> #################
> ## Model Results
> #################
> 
> #QDA
> model_rslts[2,1]<-mean(qda_train)
> model_rslts[2,2]<-mean(qda_valid)
> 
> #SVM
> model_rslts[3,1]<-mean(svm_train)
> model_rslts[3,2]<-mean(svm_valid)
> 
> #tree
> model_rslts[4,1]<-mean(tree_train)
> model_rslts[4,2]<-mean(tree_valid)
> 
> sd(qda_train)
[1] 0.04500156
> sd(qda_valid)
[1] 0.01653966
> sd(svm_valid)
[1] 0.07985823
> sd(svm_train)
[1] 0.08369601
> sd(tree_train)
[1] 0.04086982
> sd(tree_valid)
[1] 0.03911962
> 
> 
> #display results
> model_rslts
         Train Validation
CNN  1.0000000  0.6400000
QDA  0.7946667  0.6823758
SVM  0.7798333  0.6517063
Tree 0.8478333  0.6282721
> 
> xtable(model_rslts, digits=2)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Tue Mar 24 12:20:05 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 & Train & Validation \\ 
  \hline
CNN & 1.00 & 0.64 \\ 
  QDA & 0.79 & 0.68 \\ 
  SVM & 0.78 & 0.65 \\ 
  Tree & 0.85 & 0.63 \\ 
   \hline
\end{tabular}
\end{table}
> 
> train_results[,6]<-model_rslts[,1]
> valid_results[,6]<-model_rslts[,2]
> 
> train_results
           n=3       n=4       n=5       n=7      n=10      n=20
CNN  1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
QDA  0.9422222 0.9166667 0.8840000 0.8461905 0.8273333 0.7946667
SVM  0.9188889 0.8841667 0.8346667 0.8271429 0.8116667 0.7798333
Tree 0.3144444 0.6658333 0.7606667 0.8266667 0.8196667 0.8478333
> 
> valid_results
           n=3       n=4       n=5       n=7      n=10      n=20
CNN  0.5500000 0.5600000 0.5600000 0.5800000 0.6000000 0.6400000
QDA  0.5553696 0.5980431 0.6230906 0.6502988 0.6667546 0.6823758
SVM  0.6065564 0.6198043 0.6193307 0.6377291 0.6449696 0.6517063
Tree 0.3317315 0.4776712 0.5308268 0.5692829 0.5936308 0.6282721
> 
> xtable(valid_results)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Tue Mar 24 12:20:05 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrrr}
  \hline
 & n=3 & n=4 & n=5 & n=7 & n=10 & n=20 \\ 
  \hline
CNN & 0.55 & 0.56 & 0.56 & 0.58 & 0.60 & 0.64 \\ 
  QDA & 0.56 & 0.60 & 0.62 & 0.65 & 0.67 & 0.68 \\ 
  SVM & 0.61 & 0.62 & 0.62 & 0.64 & 0.64 & 0.65 \\ 
  Tree & 0.33 & 0.48 & 0.53 & 0.57 & 0.59 & 0.63 \\ 
   \hline
\end{tabular}
\end{table}
> 
> xtable(train_results)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Tue Mar 24 12:20:05 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrrr}
  \hline
 & n=3 & n=4 & n=5 & n=7 & n=10 & n=20 \\ 
  \hline
CNN & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 \\ 
  QDA & 0.94 & 0.92 & 0.88 & 0.85 & 0.83 & 0.79 \\ 
  SVM & 0.92 & 0.88 & 0.83 & 0.83 & 0.81 & 0.78 \\ 
  Tree & 0.31 & 0.67 & 0.76 & 0.83 & 0.82 & 0.85 \\ 
   \hline
\end{tabular}
\end{table}
> 
> ultima<-as.data.frame(rbind(train_results, valid_results))
> 
> fcts<-as.factor(c(rep(1, 4), rep(2, 4)))
> 
> ultima<-cbind(ultima, fcts)
Warning message:
In data.row.names(row.names, rowsi, i) :
  some row.names duplicated: 5,6,7,8 --> row.names NOT used
> 
> ultima
        n=3       n=4       n=5       n=7      n=10      n=20 fcts
1 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000    1
2 0.9422222 0.9166667 0.8840000 0.8461905 0.8273333 0.7946667    1
3 0.9188889 0.8841667 0.8346667 0.8271429 0.8116667 0.7798333    1
4 0.3144444 0.6658333 0.7606667 0.8266667 0.8196667 0.8478333    1
5 0.5500000 0.5600000 0.5600000 0.5800000 0.6000000 0.6400000    2
6 0.5553696 0.5980431 0.6230906 0.6502988 0.6667546 0.6823758    2
7 0.6065564 0.6198043 0.6193307 0.6377291 0.6449696 0.6517063    2
8 0.3317315 0.4776712 0.5308268 0.5692829 0.5936308 0.6282721    2
> 
> xtable(ultima)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Tue Mar 24 12:20:05 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrrrl}
  \hline
 & n=3 & n=4 & n=5 & n=7 & n=10 & n=20 & fcts \\ 
  \hline
1 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1 \\ 
  2 & 0.94 & 0.92 & 0.88 & 0.85 & 0.83 & 0.79 & 1 \\ 
  3 & 0.92 & 0.88 & 0.83 & 0.83 & 0.81 & 0.78 & 1 \\ 
  4 & 0.31 & 0.67 & 0.76 & 0.83 & 0.82 & 0.85 & 1 \\ 
  5 & 0.55 & 0.56 & 0.56 & 0.58 & 0.60 & 0.64 & 2 \\ 
  6 & 0.56 & 0.60 & 0.62 & 0.65 & 0.67 & 0.68 & 2 \\ 
  7 & 0.61 & 0.62 & 0.62 & 0.64 & 0.64 & 0.65 & 2 \\ 
  8 & 0.33 & 0.48 & 0.53 & 0.57 & 0.59 & 0.63 & 2 \\ 
   \hline
\end{tabular}
\end{table}
> 
> 
> #final results plot
> 
> models<-( rep(c("CNN", "QDA", "SVM", "Tree"), 6*4 ) )
> set<-( rep(c(rep("Training", 4), rep("Validation", 4)), 6) )
> acc<-c(ultima[,1], ultima[,2], ultima[,3],
+        ultima[,4], ultima[,5], ultima[,6])
> samp<-c( rep(3.0, 8), rep(4.0, 8), rep(5.0, 8),
+          rep(7.0, 8), rep(10.0, 8), rep(20.0, 8))
> mydata<-as.data.frame(cbind(models, (acc), set, as.numeric(samp) ) )
> 
> colnames(mydata)[2]<-"Acc"
> colnames(mydata)[4]<-"Samp"
> 
> 
> ultima_plot<-ggplot(data=mydata,
+             aes(x = as.numeric(as.character(mydata$Samp)),
+                 y = as.numeric(as.character(mydata$Acc)),
+                 colour = as.factor(mydata$models),
+                 shape= as.factor(mydata$set),
+                 linetype= as.factor(mydata$set),
+                 group=interaction(as.factor(mydata$models), as.factor(mydata$set))
+                 ) )+
+           geom_point(size=4)+
+           geom_line(size=2 )+
+           #geom_ribbon(aes(ymin=temp$lower, ymax=temp$upper), linetype=2, alpha=0.1)+
+ 	 	  ggtitle("Overall Results for\nGalaxy Shapes")+
+ 		  xlab("Training Size")+
+ 		  ylab("Overall Accuracy")+
+ 		  labs(colour= "Model", shape="Data Set", linetype="Data Set")+
+ 	      #scale_y_discrete(limits=c(0, 1.00))+
+           #scale_x_discrete(breaks=c(3, 4, 5, 7, 10, 20))+
+           mytheme.scat+
+           scale_colour_manual(values = c("Red", "Blue", "Green", "khaki2"))+
+           #scale_color_discrete(breaks=c("Training", "Validation"))+
+           theme(legend.text=element_text(size=18),
+                 legend.title=element_text(size=24))
> 
> ultima_plot
> 
> ggsave(filename="plots/OverallAcc_galaxy.png", plot=ultima_plot,
+        width=9, height=7)
> 
> 
> ##########################
> # Empirical SP Estimation
> ##########################
> 
> 
> labs<-as.factor(c(rep(1, dim(edge)[1]), rep(2, dim(spiral)[1]), rep(3, dim(elip)[1])) )
> mydata<-rbind(edge, spiral, elip)
> 
> 
> #counts plot
> sps<-mydata[,1]/rowSums(mydata)
> aggregate(sps~labs, FUN=mean)
  labs       sps
1    1 0.1504249
2    2 0.4121434
3    3 0.5023080
> xtable(aggregate(sps~labs, FUN=sd))
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Tue Mar 24 12:20:07 2020
\begin{table}[ht]
\centering
\begin{tabular}{rlr}
  \hline
 & labs & sps \\ 
  \hline
1 & 1 & 0.04 \\ 
  2 & 2 & 0.10 \\ 
  3 & 3 & 0.07 \\ 
   \hline
\end{tabular}
\end{table}
> 
> 
> 
> 
> #
> 
> proc.time()
   user  system elapsed 
451.886   7.191 503.676 
